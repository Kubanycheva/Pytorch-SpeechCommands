{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oO-ojbaFi9y9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchaudio import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import zipfile\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lA_5_MdYHdBM"
   },
   "outputs": [],
   "source": "zipfile.ZipFile(\"../../Downloads/Data.zip\").extractall(\"../../Downloads/Data\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPep8Y_JjB7j",
    "outputId": "04a93b23-c464-45a6-e9fd-2ddaf33a8b9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fBWXy86jB_B"
   },
   "outputs": [],
   "source": [
    "class GTZANDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, target_transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.files = []\n",
    "        for label, genre in enumerate(self.classes):\n",
    "            genre_dir = os.path.join(root_dir, genre)\n",
    "            for file in os.listdir(genre_dir):\n",
    "                if file.endswith(\".wav\"):\n",
    "                    self.files.append((os.path.join(genre_dir, file), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.files[idx]\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка загрузки {file_path}: {e}\")\n",
    "\n",
    "            return torch.zeros(1, 22050), label\n",
    "\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return waveform, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCri4OI4jCCq"
   },
   "outputs": [],
   "source": [
    "transform = transforms.MelSpectrogram(\n",
    "    sample_rate=22050,\n",
    "    n_mels=128,\n",
    "    n_fft=2048,\n",
    "    hop_length=512\n",
    ")\n",
    "# dataset = GTZANDataset(\"/content/data/genres_original\", transform=transform)\n",
    "dataset = GTZANDataset(\"/content/data/Data/genres_original\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFGk9wXgjCG4",
    "outputId": "0f63e7d1-cf46-4dde-ab55-050c2c6470b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка загрузки /content/data/Data/genres_original/jazz/jazz.00054.wav: Failed to open the input \"/content/data/Data/genres_original/jazz/jazz.00054.wav\" (Invalid data found when processing input).\n",
      "Всего удалено битых файлов: 1\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "\n",
    "# Проверка и удаление битых файлов\n",
    "bad_files = []\n",
    "for path, label in dataset.files:\n",
    "    try:\n",
    "        torchaudio.load(path)\n",
    "    except Exception as e:\n",
    "        bad_files.append(path)\n",
    "        print(f\"Ошибка загрузки {path}: {e}\")\n",
    "\n",
    "# Удаляем битые файлы из списка датасета\n",
    "dataset.files = [(p, l) for p, l in dataset.files if p not in bad_files]\n",
    "\n",
    "print(f\"Всего удалено битых файлов: {len(bad_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNQG9X-fjCKc"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "val_size   = int(0.15 * len(dataset))\n",
    "test_size  = len(dataset) - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpsOPLJCKWhd"
   },
   "outputs": [],
   "source": [
    "labels = sorted(list(set([i[1] for i in train_data])))\n",
    "label_to_index = {lab: ind for ind, lab in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPNFVUUwKX3i"
   },
   "outputs": [],
   "source": [
    "max_len = 660\n",
    "\n",
    "def collate_fn(batch):\n",
    "    spectrograms, targets = [], []\n",
    "    for waveform, label, *_ in batch:\n",
    "      spec = transform(waveform).squeeze(0)\n",
    "\n",
    "      if spec.shape[1] > max_len:\n",
    "        spec = spec[:, :max_len]\n",
    "\n",
    "      if spec.shape[1] < max_len:\n",
    "        pad_amount = max_len - spec.shape[1]\n",
    "        spec = F.pad(spec, (0, pad_amount))\n",
    "      spectrograms.append(spec)\n",
    "      targets.append(label_to_index[label])\n",
    "\n",
    "    spectrograms = torch.stack(spectrograms)\n",
    "    targets = torch.tensor(targets)\n",
    "\n",
    "    return spectrograms, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_B5MESZDKd7k"
   },
   "outputs": [],
   "source": [
    "train = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "valid = DataLoader(val_data, batch_size=64, collate_fn=collate_fn)\n",
    "test = DataLoader(test_data, batch_size=64, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTrnHKIzKfzv",
    "outputId": "051fe0b9-6e94-4578-cbd2-d73d2f1ac013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blues',\n",
       " 'classical',\n",
       " 'country',\n",
       " 'disco',\n",
       " 'hiphop',\n",
       " 'jazz',\n",
       " 'metal',\n",
       " 'pop',\n",
       " 'reggae',\n",
       " 'rock']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset.classes\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTrktp6iKhcQ"
   },
   "outputs": [],
   "source": [
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygVIk6iKKl0f"
   },
   "outputs": [],
   "source": [
    "class CheckAudio(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.first = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.AdaptiveAvgPool2d((4, 4))\n",
    "    )\n",
    "    self.second = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 4 * 4, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    x = x.unsqueeze(1)\n",
    "    x = self.first(x)\n",
    "    x = self.second(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2duOefHjCkL"
   },
   "outputs": [],
   "source": [
    "model = CheckAudio().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjMwe3lpjCnm"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxjgVyfgjCre",
    "outputId": "774316c7-2662-42c8-9b5f-dde88635d438"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, Потери: 586.1523303985596\n",
      "Эпоха 2, Потери: 130.43727445602417\n",
      "Эпоха 3, Потери: 38.75723624229431\n",
      "Эпоха 4, Потери: 27.510332822799683\n",
      "Эпоха 5, Потери: 23.98690915107727\n",
      "Эпоха 6, Потери: 22.45406150817871\n",
      "Эпоха 7, Потери: 21.83602750301361\n",
      "Эпоха 8, Потери: 21.264204621315002\n",
      "Эпоха 9, Потери: 20.447927474975586\n",
      "Эпоха 10, Потери: 19.817460536956787\n",
      "Эпоха 11, Потери: 19.118231534957886\n",
      "Эпоха 12, Потери: 18.379493713378906\n",
      "Эпоха 13, Потери: 17.889331698417664\n",
      "Эпоха 14, Потери: 17.178139328956604\n",
      "Эпоха 15, Потери: 16.62355077266693\n",
      "Эпоха 16, Потери: 16.230235695838928\n",
      "Эпоха 17, Потери: 15.426336288452148\n",
      "Эпоха 18, Потери: 14.882123470306396\n",
      "Эпоха 19, Потери: 14.493664979934692\n",
      "Эпоха 20, Потери: 13.855992555618286\n",
      "Эпоха 21, Потери: 13.40796971321106\n",
      "Эпоха 22, Потери: 12.50597733259201\n",
      "Эпоха 23, Потери: 12.155968725681305\n",
      "Эпоха 24, Потери: 11.245635867118835\n",
      "Эпоха 25, Потери: 10.873333215713501\n",
      "Эпоха 26, Потери: 10.357626795768738\n",
      "Эпоха 27, Потери: 10.420064747333527\n",
      "Эпоха 28, Потери: 10.438248991966248\n",
      "Эпоха 29, Потери: 10.567963421344757\n",
      "Эпоха 30, Потери: 10.045331239700317\n",
      "Эпоха 31, Потери: 9.420884013175964\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "  model.train\n",
    "  total_loss = 0\n",
    "  for x_batch, y_batch in train:\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "    y_pred_train = model(x_batch)\n",
    "    loss = loss_fn(y_pred_train, y_batch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "  print(f'Эпоха {epoch+1}, Потери: {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDQTvC6xL1Nq"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for x_batch, y_batch in test:\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "    y_pred_test = model(x_batch)\n",
    "    predicted = torch.argmax(y_pred_test, dim=1)\n",
    "\n",
    "    total += y_batch.size(0)\n",
    "    correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'toch models is test datasets:  {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iY-qb5_Q9AB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
